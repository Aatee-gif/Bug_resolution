{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00de31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "code_bugs_df = pd.read_csv('Code_bugs_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68622be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Time_to_Update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Critical</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Workaround</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blocker</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trivial</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Not A Bug</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status  Resolution  Time_to_Update\n",
       "0     Major  Closed     Invalid               0\n",
       "1  Critical  Closed  Workaround               2\n",
       "2   Blocker  Closed       Fixed               0\n",
       "3   Trivial  Closed   Not A Bug              15\n",
       "4     Major  Closed   Duplicate               0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_bugs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0cd3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Priority          0\n",
       "Status            0\n",
       "Resolution        0\n",
       "Time_to_Update    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_bugs_df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7111a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_resolution(val):\n",
    "    if val == 'Fixed':\n",
    "        return 'Fixed'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "code_bugs_df['Resolution'] = code_bugs_df['Resolution'].apply(simplify_resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace6519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_priority(val):\n",
    "    if val in ['Blocker', 'Critical']:\n",
    "        return 'High'\n",
    "    elif val in ['Major']:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'low'\n",
    "code_bugs_df['Priority'] = code_bugs_df['Priority'].apply(simplify_priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77222dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_Status(val):\n",
    "    if val in ['Resolved', 'Closed']:\n",
    "        return 'Resolved'\n",
    "    else:\n",
    "        return 'Open'\n",
    "code_bugs_df['Status'] = code_bugs_df['Status'].apply(simplify_Status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db8080e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Time_to_Update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medium</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medium</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Medium</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Medium</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>low</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Medium</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Medium</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Priority    Status Resolution  Time_to_Update\n",
       "0   Medium  Resolved      Other               0\n",
       "1     High  Resolved      Other               2\n",
       "2     High  Resolved      Fixed               0\n",
       "3      low  Resolved      Other              15\n",
       "4   Medium  Resolved      Other               0\n",
       "5   Medium  Resolved      Other               0\n",
       "6   Medium  Resolved      Other               1\n",
       "7      low  Resolved      Other               2\n",
       "8   Medium  Resolved      Other               0\n",
       "9   Medium  Resolved      Other               0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_bugs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eca4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "code_bugs_df['Priority'] = le.fit_transform(code_bugs_df['Priority'])\n",
    "code_bugs_df['Status'] = le.fit_transform(code_bugs_df['Status'])\n",
    "code_bugs_df['Resolution'] = le.fit_transform(code_bugs_df['Resolution'])  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43af6c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Time_to_Update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status  Resolution  Time_to_Update\n",
       "0         1       0           1               0\n",
       "1         0       0           1               2\n",
       "2         0       0           0               0\n",
       "3         2       0           1              15\n",
       "4         1       0           1               0\n",
       "5         1       0           1               0\n",
       "6         1       0           1               1\n",
       "7         2       0           1               2\n",
       "8         1       0           1               0\n",
       "9         1       0           1               0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_bugs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a92f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.57      0.70       119\n",
      "           1       0.11      0.46      0.17        13\n",
      "\n",
      "    accuracy                           0.56       132\n",
      "   macro avg       0.51      0.52      0.44       132\n",
      "weighted avg       0.83      0.56      0.65       132\n",
      "\n",
      "[[68 51]\n",
      " [ 7  6]]\n",
      "ROC AUC Score: 0.5164835164835165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X = code_bugs_df.drop(columns=['Resolution'])\n",
    "y = code_bugs_df['Resolution']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6614657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_bugs_df_encoded = pd.get_dummies(code_bugs_df, columns=['Priority', 'Status'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e511c36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       119\n",
      "           1       0.19      0.31      0.24        13\n",
      "\n",
      "    accuracy                           0.80       132\n",
      "   macro avg       0.55      0.58      0.56       132\n",
      "weighted avg       0.85      0.80      0.82       132\n",
      "\n",
      "[[102  17]\n",
      " [  9   4]]\n",
      "Predicted Probabilities:\n",
      " 0.48150251247674375\n",
      "ROC AUC Score: 0.54169360051713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = code_bugs_df_encoded.drop(columns=['Resolution'])\n",
    "y = code_bugs_df_encoded['Resolution']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Predicted Probabilities:\\n\", y_pred_proba[0])\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "215b160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       178\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.90       198\n",
      "   macro avg       0.45      0.50      0.47       198\n",
      "weighted avg       0.81      0.90      0.85       198\n",
      "\n",
      "[[178   0]\n",
      " [ 20   0]]\n",
      "ROC AUC Score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVE\\ML_IntelligentSystems\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVE\\ML_IntelligentSystems\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVE\\ML_IntelligentSystems\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = code_bugs_df_encoded.drop(columns=['Resolution'])\n",
    "y = code_bugs_df_encoded['Resolution']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ad4192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       119\n",
      "           1       0.25      0.08      0.12        13\n",
      "\n",
      "    accuracy                           0.89       132\n",
      "   macro avg       0.58      0.53      0.53       132\n",
      "weighted avg       0.84      0.89      0.86       132\n",
      "\n",
      "[[116   3]\n",
      " [ 12   1]]\n",
      "ROC AUC Score: 0.5258564964447316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVE\\ML_IntelligentSystems\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:18:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "X = code_bugs_df_encoded.drop(columns=['Resolution'])\n",
    "y = code_bugs_df_encoded['Resolution']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss',scale_pos_weight=1)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)    \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "702863b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       119\n",
      "           1       0.20      0.31      0.24        13\n",
      "\n",
      "    accuracy                           0.81       132\n",
      "   macro avg       0.56      0.59      0.57       132\n",
      "weighted avg       0.85      0.81      0.83       132\n",
      "\n",
      "[[103  16]\n",
      " [  9   4]]\n",
      "ROC AUC Score: 0.5866192630898514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae06b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVE\\ML_IntelligentSystems\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:18:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_param = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1e54f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       119\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.90       132\n",
      "   macro avg       0.45      0.50      0.47       132\n",
      "weighted avg       0.81      0.90      0.85       132\n",
      "\n",
      "[[119   0]\n",
      " [ 13   0]]\n",
      "ROC AUC Score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVE\\ML_IntelligentSystems\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVE\\ML_IntelligentSystems\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVE\\ML_IntelligentSystems\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "best_param.fit(X_train_scaled, y_train)\n",
    "y_pred = best_param.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3adf23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87       119\n",
      "           1       0.19      0.38      0.25        13\n",
      "\n",
      "    accuracy                           0.77       132\n",
      "   macro avg       0.55      0.60      0.56       132\n",
      "weighted avg       0.85      0.77      0.81       132\n",
      "\n",
      "[[97 22]\n",
      " [ 8  5]]\n",
      "ROC AUC Score after SMOTE: 0.5998707175177763\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "log_reg.fit(X_resampled, y_resampled)\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score after SMOTE:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0c5e208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.63      0.75       119\n",
      "           1       0.12      0.46      0.19        13\n",
      "\n",
      "    accuracy                           0.61       132\n",
      "   macro avg       0.52      0.55      0.47       132\n",
      "weighted avg       0.84      0.61      0.69       132\n",
      "\n",
      "[[75 44]\n",
      " [ 7  6]]\n",
      "ROC AUC Score after SMOTE: 0.5458952811893989\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "rf.fit(X_resampled, y_resampled)\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score after SMOTE:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1a85f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       119\n",
      "           1       0.20      0.23      0.21        13\n",
      "\n",
      "    accuracy                           0.83       132\n",
      "   macro avg       0.56      0.56      0.56       132\n",
      "weighted avg       0.84      0.83      0.84       132\n",
      "\n",
      "[[107  12]\n",
      " [ 10   3]]\n",
      "ROC AUC Score after SMOTE: 0.5649644473173885\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "knn.fit(X_resampled, y_resampled)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score after SMOTE:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22947d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
